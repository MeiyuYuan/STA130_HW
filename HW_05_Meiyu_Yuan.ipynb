{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a65129f",
   "metadata": {},
   "source": [
    "1. The key factor is whether the ideas are quantifiable or can be measured. This is because analysis using statistical methods requires that ideas must be expressible in terms of observable data. In contrast, ideas that are not measurable or observable will not pass statistical scrutiny and testing.\n",
    "    A good null hypothesis is clear, specific and refutable. It provides us with a criterion for determining whether there is a significant effect or difference, which is a default hypothesis. It can be checked and tested by analyzing the data, and when the results contradict the original hypothesis, the original hypothesis can be refuted and the alternative hypothesis may be valid.\n",
    "    The null hypothesis is the default state of no effect, difference, or relationship initially assumed in the aggregate for which the statistical analysis is performed. The alternative hypothesis is the opposite of the null hypothesis and indicates that there is a significant effect, difference, or relationship in the totality of the statistical analysis. We are able to analyze the data to reject the null hypothesis or prove whether the alternative hypothesis is valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502ba12",
   "metadata": {},
   "source": [
    "2. The sample value xi is a single specific data point collected from the sample, each xi represents a specific observation or measurement, and these data are actually obtained during the data collection process. The sample mean value xˉ is the average of all the data points we have collected, which can reflect the overall trend of concentration of the sample data, that is, a rough estimate of the overall situation. However, the sample mean can only represent the situation of the sample data we have collected and cannot accurately represent the population situation. The population mean μ is the true average of all the data in the overall situation we want to understand. Since the overall data cannot be collected in full, we use the sample data to estimate the population data situation, and use the test to determine whether we can reasonably estimate the actual average value of the population data from the sample data. The mean μ0 in the null hypothesis is the population mean value that we assumed before performing the data analysis, and it can be verified by examining and analyzing the sample data to see if it is valid, which means whether to accept or reject this null hypothesis.\n",
    "    So, the meaning of the sentence in the video is that the result of the statistical test is only for the population parameter ( which is the population mean μ) and not for the statistic calculated from the sample (the sample mean xˉ). Although we base the calculation of the hypothesis test on the sample data, the conclusions drawn from the test are about the overall population and not about the sample situation that represents a portion of the data. This is because we are using the sample statistic (sample mean xˉ), which is the small data set obtained from our sampling, to estimate the approximate situation of the population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ccaa5",
   "metadata": {},
   "source": [
    "link of chat log histories: https://chatgpt.com/share/670dcb10-cd80-800e-ad12-dfac97ec80eb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33977ce4",
   "metadata": {},
   "source": [
    "3. It is only when the original hypothesis is assumed to be true that we can know what will happen to the sample data when the original hypothesis is true. We are able to use the sampling distribution to estimate the probability of occurrence and distribution of a statistic in a sample, provided the original hypothesis is true. The probability that the statistic or extreme statistic we observe in the sample will occur is the p-value. In other words, the p-value enables us to know the likelihood of getting the results observed in the sample data, assuming the original hypothesis holds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7994e8",
   "metadata": {},
   "source": [
    "4. A small p-value under the assumption that the null hypothesis is true means that our observations are very uncommon, which means that the likelihood of observing the current statistic or other more extreme statistical results is very low. As a result of this low likelihood of a result, we are able to doubt that the null hypothesis is actually true and thus consider rejecting the original hypothesis.\n",
    "    Explanation: The p-value is the probability of observing the statistic or a more extreme statistic that we would observe if the null hypothesis were true. In other words, it is how probable it is that the results we get from observing the null hypothesis when it is true, including the more extreme results, will occur. The p-value will be smaller when the statistic we observe is at the more extreme end of the sample distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46341bad",
   "metadata": {},
   "source": [
    "5. Sample Values xi: Each couple's head tilt direction (left or right).\n",
    "Sample proportion xˉ: The observed proportion of couples tilting their heads to the right, which is 64.5% or 80 out of 124 couples.\n",
    "Population proportion μ: The observed proportion based on the sample, which is 0.645.\n",
    "Hypothesized population proportion μ0: The value under the null hypothesis, which is 0.5 (no tilt preference).\n",
    "Null Hypothesis H0: Humans do not have a left or right head tilt tendency when kissing, and both directions are equally likely (50/50).\n",
    "    \n",
    "    To calculate the p-value, we consider each couple's head tilt to be a separate “coin-flipping”, resulting in a 50/50 probability. Through multiple simulations we observed how many of the 124 couples tilted their heads to the right, and recorded the number of rightward tilts in each simulation.\n",
    "    Simulation process: In each simulation, we randomly generate the “tilt direction” of 124 couples, assuming that each couple has a 50% probability of tilting to the left or to the right. That is, for each of the 124 simulations of the binomial distribution, there is a 50% probability of tilting to the right and a 50% probability of tilting to the left. Then, the number of times the head was tilted to the right needed to be recorded in each simulation. After the simulation is repeated many times, we calculate how many simulations have a proportion of heads tilted to the right equal to or greater than 64.5% ( which means 80 or more couples tilted to the right). This gives us the probability of getting such an extreme result as observed when the original hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fd43db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed count of right tilts: 79\n",
      "P-value: 0.0014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n_couples = 124             # Total number of couples\n",
    "observed_proportion = 0.645 # Observed proportion of right tilts (64.5%)\n",
    "observed_count = int(n_couples * observed_proportion) # Count of right tilts (80)\n",
    "n_simulations = 10000       # Number of simulations\n",
    "\n",
    "# Simulate the head tilts\n",
    "simulated_counts = np.random.binomial(n_couples, 0.5, n_simulations)\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = np.mean(simulated_counts >= observed_count)\n",
    "\n",
    "print(f\"Observed count of right tilts: {observed_count}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880dbdd",
   "metadata": {},
   "source": [
    "p=0.0014\n",
    "Since the p-value (0.0014) is less than 0.01(0.01 ≥ p > 0.001), we have strong evidence to reject the null hypothesis H0. This suggests that there is a clear preference for head tilting in humans when kissing. Therefore we can support the alternative hypothesis that people may indeed prefer to tilt to the right when kissing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b5807",
   "metadata": {},
   "source": [
    "link of chat log histories: https://chatgpt.com/share/670df41e-e908-800e-9704-d32aca16de54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb6b1c",
   "metadata": {},
   "source": [
    "6. Smaller p-values cannot definitively prove that the original hypothesis is false, it represents the strength of the evidence against the null hypothesis. Therefore, a small p-value does not clearly prove that Fido is innocent. This is because it may indicate that the evidence is inconsistent with the hypothesis of guilt, but it does not confirm innocence. Similarly, a small p-value does not definitively prove that Fido is guilty. It may indicate that the evidence supports guilt, but does not confirm it. In conclusion, there is no specific p-value that definitively proves Fido's guilt or innocence. This is because hypothesis testing evaluates the evidence rather than drawing absolute conclusions. Moreover, based on the statistical inference of the p-value, a p-value below 0.05 or 0.01 or 0.001 can lead to the rejection of the original hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ec79b",
   "metadata": {},
   "source": [
    "7. Code for the change section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the null hypothesis population parameter value\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "# Observed test statistic: proportion of patients with positive health score change\n",
    "observed_test_statistic = (patient_data.HealthScoreChange > 0).mean()\n",
    "\n",
    "# Generate random test statistics under the null hypothesis\n",
    "simulated_test_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "# For a one-tailed test, we only look at the right tail (simulations greater than or equal to the observed)\n",
    "SimTestStats_as_or_more_extreme_than_ObsTestStat = simulated_test_statistics >= observed_test_statistic\n",
    "\n",
    "# Calculate the p-value (the proportion of simulations that are as or more extreme than the observed test statistic)\n",
    "p_value = SimTestStats_as_or_more_extreme_than_ObsTestStat.sum() / number_of_simulations\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of Simulations: \", number_of_simulations, \"\\n\\n\",\n",
    "      \"Number of simulated test statistics (under HO)\\n\",\n",
    "      'that are \"as or more extreme\" than the observed test statistic: ',\n",
    "      SimTestStats_as_or_more_extreme_than_ObsTestStat.sum(), \"\\n\\n\",\n",
    "      'p-value\\n(= simulations \"as or more extreme\" / total simulations): ', p_value, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c314cf",
   "metadata": {},
   "source": [
    "    The code changes the checking of extreme regions. Whereas in a two-tailed test we are interested in both positive and negative deviations from the null hypothesis parameter, in a one-tailed test we only check for extremes in one direction, not both sides, so the p-value should be a simulated proportion of observed test statistics that are greater than or equal to the observed test statistic when the test health score increases. In other words, the p-value is calculated as the proportion of simulated test statistics that are the same or more extreme than those observed in the right tail. By examining only one tail, the test becomes one that examines only increases in health scores, rather than both increases and decreases.\n",
    "    In a two-tailed test, we examine deviations from the original hypothesis in both directions. Compared to the hypothesized population parameter, we check whether the value is significantly higher or lower, that is, whether the increase in health scores is significantly different in either direction (positive or negative) from 0. In a one-tailed test, on the other hand, we focus on only one direction of the score increase. So we test whether the proportion of patients with a positive change in health score is significantly larger than we would expect under the null hypothesis (0.5).\n",
    "    The p-value should indeed be smaller in a one-tailed test than in a two-tailed test. Because in a one-tailed test we only consider the probability of observing an extreme value in one direction, all the extremes are distributed centrally on the same side, and the results will be more significant and the p-value will be smaller. Whereas in a two-tailed test the extremes may be distributed in both directions and some of the significant results may cancel each other out, resulting in a larger p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab0ace",
   "metadata": {},
   "source": [
    "link of chat log histories: https://chatgpt.com/share/670f00f9-34cc-800e-af3a-f9225a2e83ec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2559b57",
   "metadata": {},
   "source": [
    "8. \n",
    "Problem Introduction: \n",
    "    \n",
    "    This report is an analysis of an experiment conducted with STA130 students on statistician Ronald Fisher's tea with milk. The experiment wanted to assess whether participants were able to correctly identify the order in which tea and milk were poured into a cup based on taste alone. In the experiment we randomly selected 80 students from STA130, each of whom tasted a cup of tea and then guessed whether the milk or the tea was poured first. Of the 80 students, 49 correctly identified the pouring order. Our goal was to test whether this result was statistically significant or whether it could be due to random guessing.\n",
    "\n",
    "\n",
    "Relationship between this experiment and the original experiment by Fisher and Bristol: \n",
    "    \n",
    "    In the original experiment Dr. Bristol was more sensitive to differences in taste due to different pouring orders of tea or milk. Whereas this experiment used a sample of 80 students who may not have Dr. Bristol's grasp of the variation in taste of tea and milk. Therefore, this experiment has a larger sample size and different subjects (sample population is different in nature) compared to the original experiment, which allows for more generalized results to be obtained for the experimental parameters.\n",
    "    \n",
    "\n",
    "The population (and sample) and parameter of interest (and corresponding observed test statistic): \n",
    "    \n",
    "    Population: All STA130 students (or a broader population of individuals with similar tasting abilities).\n",
    "    Sample: A random sample of 80 STA130 students.\n",
    "    Parameter of Interest: The probability that a student can correctly identify the pouring order based on taste.\n",
    "    The observed test statistic: The number of correct guesses which is 49 out of 80 in this sample.\n",
    "    \n",
    "\n",
    "Statements of the Null Hypothesis and Alternative hypothesis:\n",
    "\n",
    "Null Hypothesis (H0):\n",
    "    Formal Version (H0 based on the population parameter): The proportion of students who can correctly identify the pouring order by taste is 0.5. H0:p=0.5.\n",
    "    Informal Interpretation Statement: Under the null hypothesis we assume that students are randomly guessing, which means that each student has a 50% chance of guessing correctly whether milk or tea was poured into the cup first.\n",
    "\n",
    "Alternative Hypothesis (HA):\n",
    "    Formal Version: The proportion of students who can correctly identify the pouring order by taste is greater than 0.5 (i.e., better than random guessing). HA:p>0.5.\n",
    "    Informal Interpretation Statement: This alternative hypothesis assumes that the students outperformed random guessing on the test, meaning that they may have been able to recognize the difference between the order in which the milk was poured first and the order in which the tea was poured first.\n",
    "\n",
    "\n",
    "Quantitative Analysis：\n",
    "    \n",
    "    In this analysis, we are testing whether students in the STA130 experiment were able to correctly identify the pouring order of tea and milk based on taste alone. Out of 80 students, 49 correctly identified the order in which tea and milk were poured. Our goal is to assess whether this result can occur by random guessing (null hypothesis). Therefore, we used simulations to calculate p-values for the analysis and then to test the original hypothesis (H0): the proportion of students correctly identifying the order is 0.5 (random guessing) and the alternative hypothesis (HA): the proportion of students correctly identifying the order is greater than 0.5 (better than random guessing).\n",
    "    \n",
    "    Methodology Code and Explanations："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c86664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0294\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations\n",
    "n_simulations = 10000\n",
    "\n",
    "# Number of students in the experiment\n",
    "n_students = 80\n",
    "\n",
    "# Null hypothesis: students are randomly guessing, with a 50% chance of getting the correct answer\n",
    "p_null = 0.5\n",
    "\n",
    "# Observed number of correct guesses\n",
    "observed_correct = 49\n",
    "\n",
    "# Simulate the experiment under the null hypothesis\n",
    "simulated_correct_guesses = np.random.binomial(n_students, p_null, n_simulations)\n",
    "\n",
    "# Calculate the p-value: proportion of simulations where the number of correct guesses is greater than or equal to 49\n",
    "p_value = np.mean(simulated_correct_guesses >= observed_correct)\n",
    "\n",
    "# Output the result\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0446e5",
   "metadata": {},
   "source": [
    "    We used np.random.seed(42) to ensure that the results were reproducible. And the number of correct guesses for each simulation was presented using np.random.binomial(n_students, p_null, n_simulations) and assuming the null hypothesis of random student guesses. We then counted simulations with a frequency of 49 or higher correct guesses, which yielded a p-value to assess whether the observation (49 correct guesses) was statistically significant (whether the randomized guesses were reasonable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c8ac0",
   "metadata": {},
   "source": [
    "Findings and Discussion:\n",
    "    \n",
    "    P-Value: The corresponding p-value is approximately 0.0294.\n",
    "    Since the p-value (0.0294) is less than 0.05 and greater than 0.01, we have moderate evidence to reject the null hypothesis. This suggests that the proportion of students who correctly identified the order of pouring is significantly higher than what would be expected by random guessing.\n",
    "\n",
    "\n",
    "Conclusion regarding the Null Hypothesis:\n",
    "\n",
    "    Since the simulation yielded a p-value of 0.0294, we rejected the null hypothesis H0: p=0.5. So the data provide enough evidence to conclude that the proportion of STA130 students who were able to correctly identify the order in which they poured the milk or the tea was greater than 0.5. Therefore, the students performed better than a random guess, which means that they were indeed able to make a guess based on the flavors that they tasted, rather than by a random guess. This means that they were indeed able to recognize the difference between the order in which the milk was poured first and the order in which the tea was poured first, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30196aec",
   "metadata": {},
   "source": [
    "link of chat log histories: https://chatgpt.com/share/670f1dfc-0edc-8004-8773-771853769e55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b027c",
   "metadata": {},
   "source": [
    "9. Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
